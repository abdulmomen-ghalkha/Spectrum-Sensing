{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN-GGN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPo7c3pSVvr2",
        "cellView": "form"
      },
      "source": [
        "#@title Library  { form-width: \"30%\" }\n",
        "import tensorflow.keras as keras\n",
        "from scipy.stats import entropy\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib \n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd \n",
        "from scipy.fft import fft\n",
        "from scipy.stats import gennorm\n",
        "import numpy as np\n",
        "from scipy.special import gamma\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense,LSTM\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import preprocessing\n",
        "from scipy.signal import savgol_filter\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Reshape, GlobalAveragePooling1D\n",
        "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
        "from keras.utils import np_utils\n",
        "!pip install -q -U tensorflow-addons\n",
        "!pip install keras-tcn\n",
        "drive.mount('/content/drive')\n",
        "# from utils.utils import save_logs\n",
        "# from utils.utils import calculate_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER0bD09qXuew",
        "cellView": "form"
      },
      "source": [
        "#@title DATA  { form-width: \"30%\" }\n",
        "def find_energy(signal, snr):\n",
        "  Y = fft(signal)\n",
        "  abs_Y = abs(Y)**2\n",
        "  r = np.mean(abs_Y)\n",
        "  return 2*snr*np.sum(r)\n",
        "def find_de(signal,beta):\n",
        "  alpha = np.log(beta*(np.sum(abs(signal-np.mean(signal))**beta))/len(signal))/beta\n",
        "  return 1/beta - np.log(beta/(2*math.gamma(1/beta))) + alpha\n",
        "def find_gp(signal):\n",
        "  return np.exp(np.mean(np.log(abs(np.array(signal)))))\n",
        "def find_lp(signal,p):\n",
        "  lp = np.mean(abs(signal)**p)\n",
        "  return lp \n",
        "def normalizeData(raw_data):\n",
        "  data = (raw_data - np.mean(raw_data))/np.sqrt(np.var(raw_data))\n",
        "  return data\n",
        "\n",
        "batch = 50\n",
        "df = pd.read_csv('Dataset/Dataset2.csv')\n",
        "raw_data = df.iloc[:,0]\n",
        "raw_data = raw_data.to_numpy()\n",
        "signal = normalizeData(raw_data[0:50000])\n",
        "lenSample = len(signal)\n",
        "# beta = 1.5\n",
        "TIME_PERIODS = 1\n",
        "\n",
        "def createTrainTest(data,Features):\n",
        "  x = data[:,0:Features]\n",
        "  y = data[:,-1]\n",
        "  return x,y\n",
        "\n",
        "def createFeature(beta,snrDB,p=0.5):\n",
        "  var = 1\n",
        "  alpha = np.sqrt((var*gamma(1/beta))/(gamma(3/beta)))\n",
        "  \n",
        "  snr = 10**(snrDB/10);\n",
        "  featuresMatrix = np.zeros(shape=(2000,5))\n",
        " \n",
        "  for i in range(0,lenSample,batch): \n",
        "    if i+batch <= lenSample:\n",
        "      noise = gennorm.rvs(beta, size=batch,scale = alpha)\n",
        "      \n",
        "      h1 = noise + np.sqrt(snr)*signal[i:i+batch]\n",
        "      h0 = gennorm.rvs(beta, size=batch,scale = alpha)\n",
        "      # features for h1\n",
        "      energy = find_energy(h1,snr)\n",
        "      de = find_de(h1,beta)\n",
        "      gp = find_gp(h1)\n",
        "      lp = find_lp(h1,p)\n",
        "      \n",
        "      featuresMatrix[i//batch] = [gp,de,lp,energy,1]\n",
        "      \n",
        "      # features for h0\n",
        "      energy = find_energy(h0,snr)\n",
        "      de = find_de(h0,beta)\n",
        "      gp = find_gp(h0)\n",
        "      lp = find_lp(h0,p)\n",
        "      \n",
        "      featuresMatrix[(lenSample+i)//batch] = [gp,de,lp,energy,0]\n",
        "      \n",
        "\n",
        "  featuresMatrix[:,0] = featuresMatrix[:,0]/max(featuresMatrix[:,0])\n",
        "  featuresMatrix[:,1] = featuresMatrix[:,1]/max(featuresMatrix[:,1])\n",
        "  featuresMatrix[:,2] = featuresMatrix[:,2]/max(featuresMatrix[:,2])\n",
        "  featuresMatrix[:,3] = featuresMatrix[:,3]/max(featuresMatrix[:,3])\n",
        "\n",
        "  np.random.shuffle(featuresMatrix)\n",
        "\n",
        "  return featuresMatrix\n",
        "\n",
        "def findPd(pf,pd):\n",
        "  temp = np.where((pf<=0.1) & (pf>0.0))[0]\n",
        "  if temp.size>0 and pd[temp[-1]] != 0.0:\n",
        "    return pd[temp[-1]]\n",
        "  else:\n",
        "    return 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3c2uvG2VvtU"
      },
      "source": [
        "snrDB = np.flip(np.arange(-20,0.5,0.5))\n",
        "\n",
        "beta = 1\n",
        "\n",
        "pd_cnn = np.ones(len(snrDB))\n",
        "pd_mlp = np.ones(len(snrDB))\n",
        "pd_fcn = np.ones(len(snrDB))\n",
        "pd_rnet =np.ones(len(snrDB))\n",
        "pd_lstm =np.ones(len(snrDB))\n",
        "pd_tcn = np.ones(len(snrDB))\n",
        "\n",
        "num_time_periods = 1\n",
        "num_classes = 1\n",
        "num_sensors=4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW93TQ49gKOF",
        "cellView": "form"
      },
      "source": [
        "#@title MLP  { form-width: \"30%\" }\n",
        "# input_layer = keras.layers.Input(num_sensors,)\n",
        "\n",
        "# # flatten/reshape because when multivariate all should be on the same axis \n",
        "# input_layer_flattened = keras.layers.Flatten()(input_layer)\n",
        "\n",
        "# # layer_1 = keras.layers.Dropout(0.1)(input_layer_flattened)\n",
        "# layer_1 = keras.layers.Dense(500, activation='relu')(input_layer_flattened)\n",
        "\n",
        "# # layer_2 = keras.layers.Dropout(0.2)(layer_1)\n",
        "# layer_2 = keras.layers.Dense(500, activation='relu')(layer_1)\n",
        "\n",
        "# # layer_3 = keras.layers.Dropout(0.2)(layer_2)\n",
        "# layer_3 = keras.layers.Dense(500, activation='relu')(layer_2)\n",
        "\n",
        "# # output_layer = keras.layers.Dropout(0.3)(layer_3)\n",
        "# output_layer = keras.layers.Dense(1, activation='sigmoid')(layer_3)\n",
        "\n",
        "# model_mlp = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# model_m.summary()\n",
        "# from tensorflow.keras.utils import plot_model\n",
        "# plot_model(model_m, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "model_mlp = Sequential()\n",
        "model_mlp.add(keras.Input(shape=(num_sensors,)))\n",
        "# model_mlp.add(Reshape((TIME_PERIODS, num_sensors), input_shape=(input_shape,)))\n",
        "# model_mlp.add(Dense(3,activation='relu'))\n",
        "model_mlp.add(Dense(100,activation='relu'))\n",
        "model_mlp.add(Dense(100,activation='relu'))\n",
        "model_mlp.add(Dense(100,activation='relu'))\n",
        "model_mlp.add(Dense(1,activation='sigmoid'))\n",
        "# print(model_mlp.summary())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu588FSeeeZF",
        "cellView": "form"
      },
      "source": [
        "#@title CNN  { form-width: \"30%\" }\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Reshape((num_sensors, 1), input_shape=(num_sensors,)))\n",
        "model_cnn.add(Conv1D(50, 1, activation='relu', input_shape=(num_sensors,1)))\n",
        "model_cnn.add(Conv1D(50, 1, activation='relu'))\n",
        "model_cnn.add(MaxPooling1D(1))\n",
        "# model_m.add(Conv1D(160, 1, activation='relu'))\n",
        "# model_m.add(Conv1D(160, 1, activation='relu'))\n",
        "model_cnn.add(Dense(50,activation='relu'))\n",
        "model_cnn.add(Dense(50,activation='relu'))\n",
        "model_cnn.add(GlobalAveragePooling1D())\n",
        "model_cnn.add(Dense(num_classes, activation='sigmoid'))\n",
        "model_cnn.save('CNN.h5')\n",
        "print(model_cnn.summary())\n",
        "# from tensorflow.keras.utils import plot_model\n",
        "# plot_model(model_m, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H_xeJFblrpC",
        "cellView": "form"
      },
      "source": [
        "#@title RESNET  { form-width: \"30%\" }\n",
        "n_feature_maps = 50\n",
        "\n",
        "input_layer = keras.layers.Input(num_sensors,)\n",
        "\n",
        "# BLOCK 1\n",
        "reshape = keras.layers.Reshape((1,num_sensors), input_shape=(num_sensors,))(input_layer)\n",
        "conv_x = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(reshape)\n",
        "conv_x = keras.layers.BatchNormalization()(conv_x)\n",
        "conv_x = keras.layers.Activation('relu')(conv_x)\n",
        "\n",
        "conv_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=5, padding='same')(conv_x)\n",
        "conv_y = keras.layers.BatchNormalization()(conv_y)\n",
        "conv_y = keras.layers.Activation('relu')(conv_y)\n",
        "\n",
        "conv_z = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=3, padding='same')(conv_y)\n",
        "conv_z = keras.layers.BatchNormalization()(conv_z)\n",
        "\n",
        "# expand channels for the sum\n",
        "shortcut_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(reshape)\n",
        "shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
        "\n",
        "output_block_1 = keras.layers.add([shortcut_y, conv_z])\n",
        "output_block_1 = keras.layers.Activation('relu')(output_block_1)\n",
        "\n",
        "# BLOCK 2\n",
        "\n",
        "conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_1)\n",
        "conv_x = keras.layers.BatchNormalization()(conv_x)\n",
        "conv_x = keras.layers.Activation('relu')(conv_x)\n",
        "\n",
        "conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
        "conv_y = keras.layers.BatchNormalization()(conv_y)\n",
        "conv_y = keras.layers.Activation('relu')(conv_y)\n",
        "\n",
        "conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
        "conv_z = keras.layers.BatchNormalization()(conv_z)\n",
        "\n",
        "# expand channels for the sum\n",
        "shortcut_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=1, padding='same')(output_block_1)\n",
        "shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
        "\n",
        "output_block_2 = keras.layers.add([shortcut_y, conv_z])\n",
        "output_block_2 = keras.layers.Activation('relu')(output_block_2)\n",
        "\n",
        "# BLOCK 3\n",
        "\n",
        "conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_2)\n",
        "conv_x = keras.layers.BatchNormalization()(conv_x)\n",
        "conv_x = keras.layers.Activation('relu')(conv_x)\n",
        "\n",
        "conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
        "conv_y = keras.layers.BatchNormalization()(conv_y)\n",
        "conv_y = keras.layers.Activation('relu')(conv_y)\n",
        "\n",
        "conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
        "conv_z = keras.layers.BatchNormalization()(conv_z)\n",
        "\n",
        "# no need to expand channels because they are equal\n",
        "shortcut_y = keras.layers.BatchNormalization()(output_block_2)\n",
        "\n",
        "output_block_3 = keras.layers.add([shortcut_y, conv_z])\n",
        "output_block_3 = keras.layers.Activation('relu')(output_block_3)\n",
        "\n",
        "# FINAL\n",
        "\n",
        "gap_layer = keras.layers.GlobalAveragePooling1D()(output_block_3)\n",
        "\n",
        "output_layer = keras.layers.Dense(1, activation='sigmoid')(gap_layer)\n",
        "\n",
        "model_rnet = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "model_rnet.save('RNET.h5')\n",
        "# model_m.summary()\n",
        "# from tensorflow.keras.utils import plot_model\n",
        "# plot_model(model_m, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6MBbBxupCGh",
        "cellView": "form"
      },
      "source": [
        "#@title LSTM  { form-width: \"30%\" }\n",
        "\n",
        "from keras.regularizers import l2\n",
        "# Import Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.regularizers import l2\n",
        "from time import time\n",
        "\n",
        "\n",
        "N = num_sensors                 # number of features\n",
        "EPOCH = 50                           # number of epochs\n",
        "LR = 5e-2                            # learning rate of the gradient descent\n",
        "LAMBD = 3e-2                         # lambda in L2 regularizaion\n",
        "DP = 0.0                             # dropout rate\n",
        "RDP = 0.0                            # recurrent dropout rate\n",
        "\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(Reshape((1,num_sensors), input_shape=(num_sensors,)))\n",
        "model_lstm.add(LSTM(input_shape=(1,num_sensors), units=8,\n",
        "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
        "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
        "               dropout=DP, recurrent_dropout=RDP,\n",
        "               return_sequences=True, return_state=False,\n",
        "               stateful=False, unroll=False\n",
        "              ))\n",
        "model_lstm.add(BatchNormalization())\n",
        "model_lstm.add(LSTM(units=8,\n",
        "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
        "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
        "               dropout=DP, recurrent_dropout=RDP,\n",
        "               return_sequences=True, return_state=False,\n",
        "               stateful=False, unroll=False\n",
        "              ))\n",
        "model_lstm.add(BatchNormalization())\n",
        "model_lstm.add(LSTM(units=8,\n",
        "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
        "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
        "               dropout=DP, recurrent_dropout=RDP,\n",
        "               return_sequences=False, return_state=False,\n",
        "               stateful=False, unroll=False\n",
        "              ))\n",
        "model_lstm.add(BatchNormalization())\n",
        "model_lstm.add(Dense(units=1, activation='sigmoid'))\n",
        "model_lstm.save('LSTM.h5')\n",
        "# model_m.summary()\n",
        "from tensorflow.keras.utils import plot_model\n",
        "# plot_model(model_m, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "dGyeSi_mtD0L"
      },
      "source": [
        "#@title encoder  { form-width: \"30%\" }\n",
        "# import tensorflow.keras as keras\n",
        "# import tensorflow as tf\n",
        "# import tensorflow_addons as tfa\n",
        "# import numpy as np\n",
        "# import time\n",
        "\n",
        "# input_layer = keras.layers.Input(3,)\n",
        "# reshape = keras.layers.Reshape((1, 3), input_shape=(3,))(input_layer)\n",
        "# # conv block -1\n",
        "# conv1 = keras.layers.Conv1D(filters=128,kernel_size=5,strides=1,padding='same')(reshape)\n",
        "# conv1 = tfa.layers.InstanceNormalization()(conv1)\n",
        "# conv1 = keras.layers.PReLU(shared_axes=[1])(conv1)\n",
        "# conv1 = keras.layers.Dropout(rate=0.2)(conv1)\n",
        "# conv1 = keras.layers.MaxPooling1D(pool_size=1)(conv1)\n",
        "# # conv block -2\n",
        "# conv2 = keras.layers.Conv1D(filters=256,kernel_size=11,strides=1,padding='same')(conv1)\n",
        "# conv2 = tfa.layers.InstanceNormalization()(conv2)\n",
        "# conv2 = keras.layers.PReLU(shared_axes=[1])(conv2)\n",
        "# conv2 = keras.layers.Dropout(rate=0.2)(conv2)\n",
        "# conv2 = keras.layers.MaxPooling1D(pool_size=1)(conv2)\n",
        "# # conv block -3\n",
        "# conv3 = keras.layers.Conv1D(filters=512,kernel_size=21,strides=1,padding='same')(conv2)\n",
        "# conv3 = tfa.layers.InstanceNormalization()(conv3)\n",
        "# conv3 = keras.layers.PReLU(shared_axes=[1])(conv3)\n",
        "# conv3 = keras.layers.Dropout(rate=0.2)(conv3)\n",
        "# # split for attention\n",
        "# attention_data = keras.layers.Lambda(lambda x: x[:,:,:256])(conv3)\n",
        "# attention_softmax = keras.layers.Lambda(lambda x: x[:,:,256:])(conv3)\n",
        "# # attention mechanism\n",
        "# attention_softmax = keras.layers.Softmax()(attention_softmax)\n",
        "# multiply_layer = keras.layers.Multiply()([attention_softmax,attention_data])\n",
        "# # last layer\n",
        "# dense_layer = keras.layers.Dense(units=256,activation='sigmoid')(multiply_layer)\n",
        "# dense_layer = tfa.layers.InstanceNormalization()(dense_layer)\n",
        "# # output layer\n",
        "# flatten_layer = keras.layers.Flatten()(dense_layer)\n",
        "# output_layer = keras.layers.Dense(units=1,activation='sigmoid')(flatten_layer)\n",
        "\n",
        "# model_m = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "# model_m.summary()\n",
        "# from tensorflow.keras.utils import plot_model\n",
        "# plot_model(model_m, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQv63gPso2KN",
        "cellView": "form"
      },
      "source": [
        "#@title FCN  { form-width: \"30%\" }\n",
        "input_layer = keras.layers.Input(num_sensors,)\n",
        "reshape = keras.layers.Reshape((1, num_sensors), input_shape=(num_sensors,))(input_layer)\n",
        "conv1 = keras.layers.Conv1D(filters=128, kernel_size=8, padding='same')(reshape)\n",
        "conv1 = keras.layers.BatchNormalization()(conv1)\n",
        "conv1 = keras.layers.Activation(activation='relu')(conv1)\n",
        "\n",
        "conv2 = keras.layers.Conv1D(filters=256, kernel_size=5, padding='same')(conv1)\n",
        "conv2 = keras.layers.BatchNormalization()(conv2)\n",
        "conv2 = keras.layers.Activation('relu')(conv2)\n",
        "\n",
        "conv3 = keras.layers.Conv1D(128, kernel_size=3,padding='same')(conv2)\n",
        "conv3 = keras.layers.BatchNormalization()(conv3)\n",
        "conv3 = keras.layers.Activation('relu')(conv3)\n",
        "\n",
        "gap_layer = keras.layers.GlobalAveragePooling1D()(conv3)\n",
        "\n",
        "output_layer = keras.layers.Dense(1, activation='sigmoid')(gap_layer)\n",
        "\n",
        "model_fcn = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "model_fcn.save('FCN.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFfzhxBAyBbz",
        "cellView": "form"
      },
      "source": [
        "#@title TCN\n",
        "from tcn import compiled_tcn\n",
        "from tcn import TCN, tcn_full_summary\n",
        "\n",
        "model_tcn = compiled_tcn(return_sequences=False,\n",
        "                         num_feat=1,\n",
        "                         num_classes=2,\n",
        "                         nb_filters=20,\n",
        "                         kernel_size=6,\n",
        "                         dilations=[2 ** i for i in range(9)],\n",
        "                         nb_stacks=1,\n",
        "                         max_len=num_sensors,\n",
        "                         use_weight_norm=True,\n",
        "                         use_skip_connections=True)\n",
        "model_tcn.save('TCN.h5')\n",
        "# model_tcn.summary()\n",
        "# from tensorflow.keras.utils import plot_model\n",
        "# plot_model(model_m, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMeHvYnlgxzc",
        "cellView": "form"
      },
      "source": [
        "#@title Model train/test  { form-width: \"30%\" }\n",
        "def trainingModel(model,tcn=False):\n",
        "  if tcn:\n",
        "    model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "                optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Hyper-parameters\n",
        "    BATCH_SIZE = 200\n",
        "    EPOCHS = 5\n",
        "\n",
        "    # Enable validation to use ModelCheckpoint and EarlyStopping callbacks.\n",
        "    history = model.fit(x_train,\n",
        "                          y_train,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          epochs=EPOCHS,\n",
        "\n",
        "                          validation_split=0.2,\n",
        "                          verbose=0\n",
        "                          )\n",
        "    y_pred = model.predict(x_test)\n",
        "\n",
        "    y_pred2=[]\n",
        "    for i in y_pred:\n",
        "      # print(i[0])\n",
        "      if(i[0]>i[1]):\n",
        "        y_pred2.append(i[1])\n",
        "      else:\n",
        "        y_pred2.append(i[1])\n",
        "    y_test2=[]\n",
        "    fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test,y_pred2)\n",
        "    return fpr_keras,tpr_keras\n",
        "\n",
        "  # callbacks_list = [\n",
        "  #     keras.callbacks.ModelCheckpoint(\n",
        "  #         filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
        "  #         monitor='val_loss', save_best_only=True),\n",
        "  #     keras.callbacks.EarlyStopping(monitor='accuracy', patience=1)\n",
        "  # ]\n",
        "\n",
        "  model.compile(\n",
        "      loss='binary_crossentropy',\n",
        "                  optimizer='adam', metrics=['binary_accuracy'])\n",
        "\n",
        "  # Hyper-parameters\n",
        "  BATCH_SIZE = 10\n",
        "  EPOCHS = 10\n",
        "\n",
        "  # Enable validation to use ModelCheckpoint and EarlyStopping callbacks.\n",
        "  history = model.fit(x_train,\n",
        "                        y_train,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        epochs=EPOCHS,\n",
        "                \n",
        "                        validation_split=0.2,\n",
        "                        verbose=0\n",
        "                        )\n",
        "  accuracy_results = model.evaluate(x_test, y_test)\n",
        "  print(\"Accuracy :\",accuracy_results)\n",
        "  # %%\n",
        "\n",
        "  # print(\"\\n--- Learning curve of model training ---\\n\")\n",
        "\n",
        "  # # summarize history for accuracy and loss\n",
        "  # plt.figure(figsize=(6, 4))\n",
        "  # plt.plot(history.history['accuracy'], \"g--\", label=\"Accuracy of training data\")\n",
        "  # plt.plot(history.history['val_accuracy'], \"g\", label=\"Accuracy of validation data\")\n",
        "  # plt.plot(history.history['loss'], \"r--\", label=\"Loss of training data\")\n",
        "  # plt.plot(history.history['val_loss'], \"r\", label=\"Loss of validation data\")\n",
        "  # plt.title('Model Accuracy and Loss')\n",
        "  # plt.ylabel('Accuracy and Loss')\n",
        "  # plt.xlabel('Training Epoch')\n",
        "  # plt.ylim(0)\n",
        "  # plt.legend()\n",
        "  # plt.show()\n",
        "\n",
        "  #%%\n",
        "\n",
        "  \n",
        "  # y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "  # %%\n",
        "\n",
        "  # print(\"\\n--- Confusion matrix for test data ---\\n\")\n",
        "\n",
        "  # y_pred_test = model_m.predict(x_test)\n",
        "  # # Take the class with the highest probability from the test predictions\n",
        "  # max_y_pred_test = np.argmax(y_pred_test, axis=1)\n",
        "  # max_y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "  # show_confusion_matrix(max_y_test, max_y_pred_test)\n",
        "\n",
        "  # # %%\n",
        "\n",
        "  # print(\"\\n--- Classification report for test data ---\\n\")\n",
        "\n",
        "  # print(classification_report(max_y_test, max_y_pred_test))\n",
        "  \n",
        "  # x_test, y_test = create_segments_and_labels(df_test,\n",
        "  #                                             TIME_PERIODS,\n",
        "  #                                             STEP_DISTANCE,\n",
        "  #                                             'LABEL')\n",
        "  # x_test = x_test.reshape(x_test.shape[0], input_shape)\n",
        "  y_pred = model.predict(x_test)\n",
        "  # if accuracy_results[1]<0.5:\n",
        "  #   y_pred = 1-y_pred\n",
        "  fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test,y_pred)\n",
        "  # plt.figure(1)\n",
        "  # plt.plot(fpr_keras, tpr_keras)\n",
        "  # plt.xlabel('False positive rate')\n",
        "  # plt.ylabel('True positive rate')\n",
        "  # plt.title('ROC curve')\n",
        "  # plt.legend(loc='best')\n",
        "  # plt.show()\n",
        "\n",
        "  return fpr_keras,tpr_keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-7ZdtmEj7h6"
      },
      "source": [
        "for i in range(len(snrDB)):\n",
        "  \n",
        "  featuresMatrix=createFeature(beta,snrDB[i])\n",
        "\n",
        "  df_train,df_test = train_test_split(featuresMatrix, test_size=0.2, random_state=42)\n",
        "  x_train, y_train = createTrainTest(df_train,num_sensors)\n",
        "  x_test, y_test = createTrainTest(df_test,num_sensors)\n",
        "\n",
        "  print(snrDB[i])\n",
        "  input_shape = (num_time_periods*num_sensors)\n",
        "  \n",
        "  x_train = x_train.reshape(x_train.shape[0], input_shape)\n",
        "  \n",
        "  x_train = x_train.astype(\"float32\")\n",
        "  y_train = y_train.astype(\"float32\")\n",
        "\n",
        "  x_test = x_test.reshape(x_test.shape[0], input_shape)\n",
        "\n",
        "  x_test = x_test.astype(\"float32\")\n",
        "  y_test = y_test.astype(\"float32\")\n",
        "\n",
        "  fpr_cnn,tpr_cnn = trainingModel(model_cnn)\n",
        "  pd_cnn[i]=findPd(fpr_cnn,tpr_cnn)\n",
        "\n",
        "  fpr_fcn,tpr_fcn = trainingModel(model_fcn)\n",
        "  pd_fcn[i]=findPd(fpr_fcn,tpr_fcn)\n",
        "\n",
        "  fpr_mlp,tpr_mlp = trainingModel(model_mlp)\n",
        "  pd_mlp[i]=(findPd(fpr_mlp,tpr_mlp))\n",
        "\n",
        "  fpr_rnet,tpr_rnet = trainingModel(model_rnet)\n",
        "  pd_rnet[i]=(findPd(fpr_rnet,tpr_rnet))\n",
        "  \n",
        "  fpr_lstm,tpr_lstm = trainingModel(model_lstm)\n",
        "  pd_lstm[i]=(findPd(fpr_lstm,tpr_lstm))\n",
        "\n",
        "  fpr_tcn,tpr_tcn = trainingModel(model_tcn,tcn=True)\n",
        "  pd_tcn[i]=(findPd(fpr_tcn,tpr_tcn))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5DME7VJX8dP"
      },
      "source": [
        "# plt.plot(snrDB,pd_cnn_gp,label = 'CNN_gp')\n",
        "# plt.plot(snrDB,pd_cnn_de,label = 'CNN_de')\n",
        "# plt.plot(snrDB,pd_cnn_lp,label = 'CNN_lp')\n",
        "# plt.plot(snrDB,pd_cnn,label = 'CNN_raw')\n",
        "# plt.plot(snrDB,pd_lstm_gp,label = 'lstm')\n",
        "# plt.plot(snrDB,pd_mlp_gp,label = 'MLP')\n",
        "fig = plt.figure()\n",
        "# plt.plot(snrDB,pd_rnet,label = 'ResNet')\n",
        "# plt.plot(snrDB,pd_lstm,label = 'LSTM')\n",
        "plt.plot(snrDB, pd_cnn, label = 'CNN') #plt.plot(snrDB_new,pd_lp,label = 'LP')\n",
        "plt.plot(snrDB,pd_mlp,label = 'MLP')\n",
        "plt.plot(snrDB,pd_fcn,label = 'FCN')\n",
        "# plt.plot(snrDB_new,pd_tcn,label = 'TCN')\n",
        "plt.xlim([-20,0])\n",
        "plt.xlabel('SNR (dB)',fontsize=16)\n",
        "plt.ylabel('Probability of detection (Pd)',fontsize=16)\n",
        "# plt.plot(snrDB_tcn,pd_tcn_gp,label = 'tcn')\n",
        "# plt.plot(snrDB,pd_fcn_gp,label = 'FCN')\n",
        "plt.legend(fontsize=12)\n",
        "# plt.show()\n",
        "# fig.savefig('raw.eps')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}